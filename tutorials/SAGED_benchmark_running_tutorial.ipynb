{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec846629",
   "metadata": {},
   "source": [
    "### **Pipeline.run_benchmark Tutorial**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691d31d8",
   "metadata": {},
   "source": [
    "The `Pipeline.run_benchmark` method in the SAGED library performs an end-to-end benchmarking process. This includes generating responses, extracting features, and analyzing data. This notebook demonstrates how to set up and execute the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c2099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from your_module.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Example function for generation (Replace with actual generation logic)\n",
    "def example_function():\n",
    "    return \"Generated data example\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0baa32",
   "metadata": {},
   "source": [
    "#### **Define Configurations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4240accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = {\n",
    "    \"generation\": {\n",
    "        \"require\": True,\n",
    "        \"generate_dict\": {\n",
    "            \"example_generation\": example_function  # Replace with a valid function\n",
    "        },\n",
    "        \"generation_saving_location\": \"output/generated_benchmark.csv\",\n",
    "        \"generation_list\": [\"example_generation\"]\n",
    "    },\n",
    "    \"extraction\": {\n",
    "        \"feature_extractors\": [\"sentiment_classification\", \"toxicity_classification\"],\n",
    "        \"calibration\": True,\n",
    "        \"extraction_saving_location\": \"output/extracted_features.csv\",\n",
    "        \"extractor_configs\": {\n",
    "            \"sentiment_classification\": {\"some_param\": \"value\"}  # Example config\n",
    "        }\n",
    "    },\n",
    "    \"analysis\": {\n",
    "        \"specifications\": [\"concept\", \"source_tag\"],\n",
    "        \"analyzers\": [\"mean\", \"selection_rate\"],\n",
    "        \"analyzer_configs\": {\n",
    "            \"selection_rate\": {\"standard_by\": \"mean\"}\n",
    "        },\n",
    "        \"statistics_saving_location\": \"output/statistics.csv\",\n",
    "        \"disparity_saving_location\": \"output/disparities.csv\"\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f084992c",
   "metadata": {},
   "source": [
    "#### **Running the Benchmark**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377606a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the domain\n",
    "domain = \"example_domain\"\n",
    "\n",
    "# Run the benchmark\n",
    "Pipeline.run_benchmark(config=config, domain=domain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7aeddc4",
   "metadata": {},
   "source": [
    "#### **Outputs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1d71e6",
   "metadata": {},
   "source": [
    "\n",
    "The following outputs will be generated:\n",
    "1. **Generated Benchmark**: Saved to `generation[\"generation_saving_location\"]`.\n",
    "2. **Extracted Features**: Saved to `extraction[\"extraction_saving_location\"]`.\n",
    "3. **Analysis Statistics**: Saved to `analysis[\"statistics_saving_location\"]`.\n",
    "4. **Disparities**: Saved to `analysis[\"disparity_saving_location\"]`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90384fd",
   "metadata": {},
   "source": [
    "#### **Example Output Inspection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0912b7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load generated benchmark\n",
    "generated_benchmark = pd.read_csv(\"output/generated_benchmark.csv\")\n",
    "print(generated_benchmark.head())\n",
    "\n",
    "# Load extracted features\n",
    "extracted_features = pd.read_csv(\"output/extracted_features.csv\")\n",
    "print(extracted_features.head())\n",
    "\n",
    "# Load analysis statistics\n",
    "statistics = pd.read_csv(\"output/statistics.csv\")\n",
    "print(statistics.head())\n",
    "\n",
    "# Load disparities\n",
    "disparities = pd.read_csv(\"output/disparities.csv\")\n",
    "print(disparities.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91ac8c8",
   "metadata": {},
   "source": [
    "#### **Notes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d42937",
   "metadata": {},
   "source": [
    "\n",
    "- Ensure all paths in `config` exist or adjust them to your environment.\n",
    "- Validate the functions provided in `generation[\"generate_dict\"]` to avoid runtime errors.\n",
    "- Review outputs to refine configurations and improve benchmarking results.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
